Axel Y. Rivera
University of Utah
axel.rivera@utah.edu

Mary Hall
University of Utah
mhall@cs.utah.edu

Boyana Norris
University of Oregon
norris@cs.uoregon.edu 

CHiLL expansion for ORIO
date: 10/16/2014


Updates:

	10-16-14:	Cuda command accepts performance parameters to study different thread and block decomposition.
			If two performance parameters for the grid are the same, it won't be tested.
			Fixed some bugs related to code cleaning.
			Fuse added
			Distribute added

	05-26-14:	Unroll added (see How to write annotations).
			Tile and Unroll accepts the values from performance_param or the user can input the exact amount.

	05-24-14:	New interface for adding cuda CHiLL commands (see How to write annotations).
			Cleaner implementation
			Use the input_vars and input_params definitions as defines and variables information.
			Currently, it allows cuda, tile, permute and copy to registers, other functions comming in the future.
			If 2 or more kernels are created, the interface automatically reorganize the code in the following way:

				cuda-mallocs
				cuda-mem-copy (host to device)
				kernel calls
				cuda-mem-copy (device to host)
				cuda-free

			  This optimization permites better performance.

			The timing information provided by Orio is an overall information of the fastest run. The module was extended to 
			    create an extra folder (times) with the output of each implemenation and the time spent on each kernel. 
			    From here it is easy to implement a bash or an expansion for Orio to have a more accurate measurment (future work).

Files:

	Orio/orio/module/chill:

		chill.py		| Module that takes CHiLL annotaions from c file and call CUDA-CHiLL
		README			| This file

	Orio/testsuit/sandbox/chill/mm
	
		mm.c			| Classic matrix multiply example
		clean.sh		| Bash file for cleaning


	Orio/testsuit/sandbox/chill/nekbone

		tensor.c		| A tensor-contraction example (Based on nekbone)
		clean.sh		| Bash file for cleaning


	Orio/testsuit/sandbox/chill/nwchem

		nwd1.c			| Another tensor-contraction example (Based on nekbone)
		clean.sh		| Bash file for cleaning

How to run:

	This is a module that allows ORIO call CHiLL. Examples are located at 
	Orio/testsuit/sandbox/chill. To run Orio with a file:  orcc -v file.c. \
        This module will create three extra folders and three extra files:

		- recipes:	  all recipes output will be located here
		- outputs:	  outputs from recipies will be located here
		- times:	  timing for each implementation and each kernel
		-_orio_chill_.c:  function created for CHiLL
		-_orio_chill_.h:  Header file for link the CUDA generated files
		-_file.c:	  Orio decision for best output

How to write annotation:

	Setup everything else like Orio (check Orio reference Manual). To start CHiLL add "/*@ begin CHiLL(", then add the 
	annotations as needed. The supported annotations are:

		-stm(#,(loops),outVar)				Add a statement, with the loops and the output variable
								# = integer value starting in 0
								(loops) = array of strings with the loop indexes
								outVar = string with the output variable

		-tile(#,index,performance_param,control)	Tile loop "index" using the values of "peformance_params"
								# = integer value representing the statement related to the loop
								index = string with the loop index to be tiled
								performance_param = Variable used from performance_param or exact amount (integer)
								control = name for the generated tiled loop

		-permute(#,(newOrder))				Permute the loop nest at specific statement
								# = integer value representing statement related to the loop
								(newOrder) = array of string with the new order of the loop nest

		-cuda(#,block={bx,by},thread={tx,ty})		Generate CUDA kernel with thread/block decomposition specified
								# = integer representing the loop nest to be turned into CUDA
								bx = string for CUDA blocks in X dimension, or performance_param array
								by = string for CUDA blocks in Y dimension, or performance_param array
								tx = string for CUDA threads in X dimension, or performance_param array
								ty = string for CUDA threads in Y dimension, or performance_param array
	
		-unroll(#,index,performace_param)		Unroll loop "index" at statement #
								# = integer representing the loop nest or statement
								index = loop index to be unrolled
								performance_param = Variable from performance_params or exact amount (integer)

		-fuse(statements)				Fuse the loops for the list of statements
								statements = list of statements to be fused

		-distribute(loop_level)				Distributes the loops at specified loop level
								loop_level = integer representing the loop level
		
	Close the CHiLL annotations with  ") @*/", then add your code. After the code, add "/*@ end CHiLL @*/".
	These are preliminary implementation for creating annotaiton related to CHiLL in a simpler manner. Make sure
	to always declare the statements (stm) before using them. Check the examples to understand these annotations.
	It is recommended to check tensor.c since it have multiple loop nests.

Other important stuffs

	Be sure to have installed a version of nvcc (CUDA-Toolkit 5.5 prefered) is installed  as well CUDA-CHiLL:

		-CUDA-Toolkit		| https://developer.nvidia.com/cuda-downloads
		-CUDA-CHiLL		| http://ctop.cs.utah.edu/downloads/chill.tar.gz
		
	This tool was tested and verified with binary operations (one output and two inputs), it isn't secure for more than 2 inputs for now.
	Make sure there is a copy of the cudaize.lua file provided by CUDA-CHiLL ({CHILL-SRC}/examples/cuda-chill/cudaize.lua) in your working directory (to be fixed later).
	Please, understand the examples before start making your own files.
	Currently it doesn't support an external recipe, but it will be added in the future.
	input_params currently accept only one value.
	input_vars curently accept only one value.
